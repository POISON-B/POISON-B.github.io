---
layout: posts
title: 'python多线程学习笔记'
date: 2019-03-05 21:20:26 +08:00
categories: python
tags: python
---
<!-- TOC -->autoauto- [1. python 多线程第一课](#1-python-多线程第一课)auto    - [1.0.1. 举例说明多线程操作：](#101-举例说明多线程操作)auto  - [1.1. 简单多线程实例：](#11-简单多线程实例)auto    - [1.1.1. 、函数方式实现](#111-函数方式实现)auto    - [1.1.2. 、类方式实现](#112-类方式实现)auto  - [1.2. 线程间的通信](#12-线程间的通信)auto    - [1.2.1. 、共享变量(不推荐)](#121-共享变量不推荐)auto      - [1.2.1.1. 、Lock](#1211-lock)auto      - [1.2.1.2. 、RLock (可重入的锁)](#1212-rlock-可重入的锁)auto  - [1.3. 、queue 通信](#13-queue-通信)auto    - [1.3.1. queue 常用方法介绍](#131-queue-常用方法介绍)auto  - [Condition](#condition)auto  - [Semaphore](#semaphore)auto  - [Timer 定时器](#timer-定时器)auto  - [线程池](#线程池)auto    - [1、简单写法](#1简单写法)auto    - [2、批量提交](#2批量提交)auto    - [3、executor.map()方法](#3executormap方法)auto    - [4、wait()阻塞方法](#4wait阻塞方法)autoauto<!-- /TOC -->
# 1. python 多线程第一课

说到 python 多线程，绕不开的话题就是 GIL(详情不赘述) GIL 使得同一时刻只有一个线程在一个 CPU 上执行字节码，，无法将多个线程映射到多个 cpu 上执行，这就使得 python 的多线程性能受限。

### 1.0.1. 举例说明多线程操作：

_有一个爬虫，需要爬取一个网站的所有文章，必须做两步操作。
  1、抓取所有文章列表 url。
  2、根据文章 url 抓取文章详细内容。
这两个步骤如果不用多线程，就必须先执行第 1 步，当所有文章列表抓取完成后，再执行第 2 步。如果使用多线程，可以实现，先执行第一步，抓取文章 url 放入共享变量，接着执行第 2 不取出共享变量中的 url 抓取文章详情。几乎同步执行，提高爬虫效率。_

## 1.1. 简单多线程实例：

### 1.1.1. 、函数方式实现

```
import time
import threading

def get_detail_html(url):
    """
    获取文章的详细内容
    :param url:
    :return:
    """
    print("get detail html started")
    time.sleep(2)
    print("get detail html end")


def get_detail_url(url):
    """
    获取文章url
    :param url:
    :return:
    """
    print("get detail url started")
    time.sleep(4)
    print("get detail url end")

if  __name__ == "__main__":
    # windows下python多线程操作必须放在mian下，linux不存在
    # target =============> 后面是需要执行的函数名， 注意只能是函数名，不能是函数调用
    # args   =============> 后面是函数需要的参数，注意必须是元组
    thread1 = threading.Thread(target=get_detail_url, args=("url",), daemon=True)
    thread2 = threading.Thread(target=get_detail_html, args=("url",))

    start_time = time.time()

    # 设置为守护线程。当主线程结束时，不要管子线程是否执行完毕都直杀掉所有线程
    # 此设置也可在，实例化Thread时添加daemon参数实现
    # thread1.daemon = True
    thread2.daemon = True

    # 启动子线程
    thread1.start()
    thread2.start()

    # 等待上面两个子线程执行完毕。才继续向下执行主线程。
    thread1.join()
    thread2.join()
    print ("last time: {}".format(time.time()-start_time))

```

### 1.1.2. 、类方式实现

```
import time
import threading


class GetDetailHtml(threading.Thread):
    """
    继承threading.Thread类
    """
    def __init__(self, name):
        super().__init__(name=name)

    def run(self):
        """
        重写run方法，程序的具体逻辑
        :return:
        """
        print("get detail html started")
        time.sleep(2)
        print("get detail html end")


class GetDetailUrl(threading.Thread):
    def __init__(self, name):
        super().__init__(name=name)

    def run(self):
        print("get detail url started")
        time.sleep(4)
        print("get detail url end")

if  __name__ == "__main__":
    thread1 = GetDetailHtml("get_detail_html")
    thread2 = GetDetailUrl("get_detail_url")
    start_time = time.time()
    thread1.start()
    thread2.start()

    thread1.join()
    thread2.join()

    print ("last time: {}".format(time.time()-start_time))

```

## 1.2. 线程间的通信

背景介绍：

线程之间为什么需要通信？
通常在多线程应用中,完成一个任务是需要几个线程协助的。以上面的爬虫例子来说，子线程 1 爬取文章列表 url，子线程 2 则需要根据子线程 1 抓取的文章 url 来抓取文章详细内容，这一来一回之间必然涉及到线程间的通信问题

线程间的通信方式

### 1.2.1. 、共享变量(不推荐)

代码说明：

```
import time
import threading
ditail_url_list = []

def get_detail_html(urls):
    """
    获取文章的详细内容
    :param url:
    :return:
    """
    while True:
      print("get detail html started")
      if urls:
          # 判断共享变量是否有值， 弹出列表中的最后一个值
          url = urls.pop()
          time.sleep(2)
          print("get detail html end")


def get_detail_url(urls):
    """
    获取文章url
    :param url:
    :return:
    """
    print("get detail url started")
    # 将抓取的文章url放入共享列表里
    urls.append('url')
    time.sleep(4)
    print("get detail url end")

if  __name__ == "__main__":
    thread1 = threading.Thread(target=get_detail_url, args=("url",))
    thread2 = threading.Thread(target=get_detail_html, args=("url",)
    start_time = time.time()
    thread1.daemon = True
    thread2.daemon = True
    thread1.start()
    thread2.start()
    thread1.join()
    thread2.join()
    print ("last time: {}".format(time.time()-start_time))
```

缺点：共享变量存在一个致命缺点，（**线程安全问题**）  
代码说明：

```
import threading

test_number = 0

def test_add():
    """
    执行共享变量加1操作
    :return:
    """
    # global关键字，声明全局作用域，使函数能修改全局变量的值
    global test_number

    for n in range(1000000):
        test_number += 1

def test_subtraction():
    """
    执行共享变量减1操作
    :return:
    """
    global test_number

    for n in range(1000000):
        test_number -= 1

if __name__ == '__main__':
    thread1 = threading.Thread(target=test_add, daemon=True)
    thread2 = threading.Thread(target=test_subtraction, daemon=True)
    thread1.start()
    thread2.start()

    thread1.join()
    thread2.join()

    print(test_number)
```

运行以上代码可以看见每次的结果都是不一样的，依常理来不管运行几次 ”test_number“ 的值都应该是固定的 0，因为我先加 1000000 次完了再减 1000000 次。但是真实结果却不是这样的，这说明了使用共享变量来实现线程间的通信是不安全的。

**形成原因：这是因为在线程运行中 GIL 适当的时候释放的(适当时候的意思：python 会根据字节码的执行行数自己判断或者是根据时间片来释放 GIL，还会在遇到 io 操作时自动释放 GIL)。 关于 io 操作自动释放 GIL 锁的特性，使得 python 多线程在 io 频繁的情况下是非常适用的**

解决方法： 根据问题形成原因可想到解决方法是，当一个子线程在操作时，其他变量就不能操作，必须等到上个子线程操作完成后，非能继续操作。这就引申出了 python 多线程编程中的锁概念。

#### 1.2.1.1. 、Lock

代码说明：

```
import threading
from threading import Lock

test_number = 0

def test_add(lock):
    """
    执行共享变量加1操作
    :return:
    """
    # global关键字，声明全局作用域，使函数能修改全局变量的值
    global test_number

    for n in range(1000000):
        # 获得锁。成功后往下执行,不成功就会一直等待直到获得锁，所以一定要用完锁后释放锁
        lock.acquire()

        # 再一次视图获取锁，此时会形成死锁问题，在acquire后必须要release
        # lock.acquire()
        test_number += 1

        # 释放锁，不然其他代码段将不能运行
        lock.release()

def test_subtraction(lock):
    """
    执行共享变量减1操作
    :return:
    """
    global test_number

    for n in range(1000000):
        lock.acquire()
        test_number -= 1
        lock.release()

if __name__ == '__main__':
    lock = Lock()
    thread1 = threading.Thread(target=test_add, args=(lock,), daemon=True)
    thread2 = threading.Thread(target=test_subtraction, args=(lock,), daemon=True)
    thread1.start()
    thread2.start()

    thread1.join()
    thread2.join()

    print(test_number)

```

总结：用锁的方法可以解决线程安全，但是也存在一些问题，**影响性能，不注意会形成死锁**

#### 1.2.1.2. 、RLock (可重入的锁)

上面的 Lock 存在一个问题，不能在一个 acquire 执行后不 release 掉的情况下，再一次 acquire，这将让程序陷入死锁中从而不能往下执行。RLock 解决了这个问题

代码说明：

```
import threading
from threading import RLock

test_number = 0

def test_add(lock):
  """
  执行共享变量加1操作
  :return:
  """
  # global关键字，声明全局作用域，使函数能修改全局变量的值
  global test_number

  for n in range(1000000):
      lock.acquire()
      lock.acquire()

      test_number += 1
      lock.release()
      lock.release()

def test_subtraction(lock):
  """
  执行共享变量减1操作
  :return:
  """
  global test_number

  for n in range(1000000):
      lock.acquire()
      test_number -= 1
      lock.release()


if __name__ == '__main__':
  lock = RLock()
  thread1 = threading.Thread(target=test_add, args=(lock,), daemon=True)
  thread2 = threading.Thread(target=test_subtraction, args=(lock, ), daemon=True)
  thread1.start()
  thread2.start()

  thread1.join()
  thread2.join()

  print(test_number)
```

总结：解决了不能重复 acquire 的问题。**注意：acquire 和 release 必须成对出现，即有几个 acquire 就必须有相应个数的 release。不然还会出现死锁问题**

## 1.3. 、queue 通信

使用 python 自带的消息队列来实现线程间的通信。  
代码说明：

```
from queue import Queue
import time
import threading


def get_detail_html(queue):
    #爬取文章详情页
    while True:
        # 从queue中获得值，如果queue里没值会一直阻塞在此处
        url = queue.get()
        print("get detail html started")
        time.sleep(2)
        print("get detail html end")


def get_detail_url(queue):
    # 爬取文章列表页
    while True:
        print("get detail url started")
        time.sleep(4)
        for i in range(20):
            # 将值写入queue
            queue.put("http://projectsedu.com/{id}".format(id=i))
        print("get detail url end")



if  __name__ == "__main__":
    # 设置队列的空间大小，当队列满了时put()方法阻塞，直到队列有空间，以节约内存。
    detail_url_queue = Queue(maxsize=1000)
    thread_detail_url = threading.Thread(target=get_detail_url, args=(detail_url_queue,))
    for i in range(10):
        html_thread = threading.Thread(target=get_detail_html, args=(detail_url_queue,))
        html_thread.start()

    # 向队列发送task_done信号。
    detail_url_queue.task_done()

    # 阻塞主线程，等待task_done信号，退出程序
    detail_url_queue.join()
```

### 1.3.1. queue 常用方法介绍

get() =====> 从队列中取值(阻塞)
put() =====> 将值写入队列
get_nowait() =====> 从队列中取值(异步)
put_nowait() =====> 将值写入队列(异步)
qsize() =====> 获取队列的长度
empty() =====> 判断队列是否为空
full() =====> 判断队列是否已满
task_done() =====> 发送队列关闭信号
join() =====> 阻塞主线程，直到接收 task_done 信号

## Condition

用于复杂的线程间通信，条件变量

代码说明：

```
import threading


class XiaoAi(threading.Thread):
    def __init__(self, cond):
        super().__init__(name="小爱")
        self.cond = cond

    def run(self):
        with self.cond:
            self.cond.wait()  # 释放锁，阻塞等待通知
            print("{} : 在 ".format(self.name))
            self.cond.notify() # 发送通知信号

            self.cond.wait()
            print("{} : 好啊 ".format(self.name))
            self.cond.notify()

            self.cond.wait()
            print("{} : 君住长江尾 ".format(self.name))
            self.cond.notify()

            self.cond.wait()
            print("{} : 共饮长江水 ".format(self.name))
            self.cond.notify()

            self.cond.wait()
            print("{} : 此恨何时已 ".format(self.name))
            self.cond.notify()

            self.cond.wait()
            print("{} : 定不负相思意 ".format(self.name))
            self.cond.notify()

class TianMao(threading.Thread):
    def __init__(self, cond):
        super().__init__(name="天猫精灵")
        self.cond = cond

    def run(self):
        with self.cond:
            print("{} : 小爱同学 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 我们来对古诗吧 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 我住长江头 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 日日思君不见君 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 此水几时休 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 只愿君心似我心 ".format(self.name))
            self.cond.notify()
            self.cond.wait()


if __name__ == "__main__":
    from concurrent import futures
    cond = threading.Condition()
    xiaoai = XiaoAi(cond)
    tianmao = TianMao(cond)

    # 启动顺序很重要
    # 在调用with cond之后才能调用wait或者notify方法
    # condition有两层锁， 一把底层锁会在线程调用了wait方法的时候释放， 上面的锁会在每次调用# wait的时候分配一把并放入到cond的等待队列中，等到notify方法的唤醒
    # wait()方法必须是在调用acquier()方法之后才能使用
    xiaoai.start()
    tianmao.start()

```

## Semaphore

用于控制进入数量的锁。

代码说明：

```
import threading
import time

class HtmlSpider(threading.Thread):
    def __init__(self, url, sem):
        super().__init__()
        self.url = url
        self.sem = sem

    def run(self):
        time.sleep(2)
        print("got html text success")
        self.sem.release() # release()方法将已占有的空间释放，执行一次释放一个。

class UrlProducer(threading.Thread):
    def __init__(self, sem):
        super().__init__()
        self.sem = sem

    def run(self):
        for i in range(20):
            self.sem.acquire() # acquire()方法将减少可用空间，当空间为0时，线程阻塞直到有空余空间为止
            html_thread = HtmlSpider("https://baidu.com/{}".format(i), self.sem)
            html_thread.start()

if __name__ == "__main__":
    # 3为设定的Semaphore空间
    sem = threading.Semaphore(3)
    url_producer = UrlProducer(sem)
    url_producer.start()

```

## Timer 定时器

代码说明：

```
import threading

def hello(name):
     print (f"hello {name}")

if __name__ == "__main__":
    # 接收两个固定参数，执行间隔时间， 执行函数名和参数
    timer = threading.Timer(2.0, hell, args=("world",))
    timer.start()

```

## 线程池

### 1、简单写法

```
import time
from concurrent.futures import ThreadPoolExecutor

def get_html(times):
    time.sleep(times)
    print("get page {} success".format(times))
    return times

if __name__ == '__main__':
    # 实例化线程池，设置最大工作数
    executor = ThreadPoolExecutor(max_workers=2)

    # 通过submit函数提交执行的函数到线程池中, submit 是立即返回
    task1 = executor.submit(get_html, (3))
    task2 = executor.submit(get_html, (2))

    # 查看任务是否执行成功
    print(task1.done())

    # 得到线程执行的结果，阻塞方法
    print(task1.result())

    # 关闭子线程，但是任务在执行中或执行完成是不能关闭的，在未开始之前可以关闭
    print(task2.cancel())
```

### 2、批量提交

通过 as_completed()方法获取任务执行结果，顺序不定谁先完成就先返回谁

代码说明：

```
import time
from concurrent.futures import ThreadPoolExecutor, as_completed


def get_html(times):
    time.sleep(times)
    print("get page {} success".format(times))
    return times


if __name__ == '__main__':

    executor = ThreadPoolExecutor(max_workers=2)
    urls = [3,2,4]

    # 批量提交任务
    all_task = [executor.submit(get_html, (url)) for url in urls]

    # as_completed()方法直接返回执行完成的任务的结果
    for future in as_completed(all_task):
        data = future.result()
        print("get {} page".format(data))

```

### 3、executor.map()方法

更简洁的写法

代码说明：

```
import time
from concurrent.futures import ThreadPoolExecutor


def get_html(times):
    time.sleep(times)
    print("get page {} success".format(times))
    return times

if __name__ == '__main__':

    executor = ThreadPoolExecutor(max_workers=2)
    urls = [3,2,4]
    # 返回循序和任务执行顺序相同
    for data in executor.map(get_html, urls):
        print("get {} page".format(data))

```

### 4、wait()阻塞方法

代码说明

```
import time
from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED


def get_html(times):
    time.sleep(times)
    print("get page {} success".format(times))
    return times

executor = ThreadPoolExecutor(max_workers=2)
urls = [3,2,4]

# 批量提交任务
all_task = [executor.submit(get_html, (url)) for url in urls]
wait(all_task, return_when=FIRST_COMPLETED)
for data in executor.map(get_html, urls):
    print("get {} page".format(data))
print("main")
```

阻塞种类有 3 种 默认(ALL_COMPLETED)
FIRST_COMPLETED =====> 阻塞至第一个线程完成
FIRST_EXCEPTION =====> 阻塞至个线程发生错误或未完成
ALL_COMPLETED =====> 阻塞至所有线程完成

**————————————END—————————**
